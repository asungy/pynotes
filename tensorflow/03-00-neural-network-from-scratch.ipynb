{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b31be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "using Printf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf1024",
   "metadata": {},
   "source": [
    "# Neural Networks From Scratch\n",
    "The simplest neural network possible can be implemented in a few lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d712df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_network (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function neural_network(input, weight)\n",
    "    prediction = input * weight\n",
    "    return prediction\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0860618",
   "metadata": {},
   "source": [
    "All a neural network does is it takes some input data and manipulates it in some way. Really, they're just mathematical functions. In this case, it's a straight line, that goes through origin (in the form of $y=mx+b$).\n",
    "\n",
    "Before we continue, it helps to lay down some context for our neural network. Every neural network has a purpose. Some networks are used to categorize images, predict stock prices, or identify tumors in patients. That being said, it helps to define some metric of utility for our neural network.\n",
    "\n",
    "Let's try to use our neural network to predict whether a student will pass or fail a test based on amount of sleep they got the night before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a6daba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0.65"
     ]
    }
   ],
   "source": [
    "# The input data\n",
    "sleep_hours = [6.50, 8.25, 8.00, 5.75, 4.00, 9.00]\n",
    "\n",
    "# Defining the input and weight\n",
    "input = sleep_hours[1]\n",
    "weight = 0.1\n",
    "\n",
    "# Making a prediction\n",
    "prediction = neural_network(input, weight)\n",
    "\n",
    "# Printing the result\n",
    "@printf \"Prediction: %.2f\" prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb36677c",
   "metadata": {},
   "source": [
    "So what is this saying? We can interpret that prediction result as saying \"a student who slept 6.5 hours the night prior to the test has a 65% chance of passing it\". We intuitively know this statement by itself is inaccurate. The weight was set arbitrarily at `0.1` so any input we give our network will simply multiply it by 0.1. Also, there must certainly be other factors that influence the chance of passing a test, such as study time, subject difficulty, etc. While what we have right now is technically a neural network, it's very clear, it's not a very good one.\n",
    "\n",
    "When building a neural network, it is not only important to consider what inputs you provide, but also, how hard it is to really measure it. For example, measuring time spent sleeping is pretty straightforward. Start a timer before you sleep and stop the timer when you wake up. Of course, you can take a more analytical approach and measure the amount of time spent in each sleep cycle stage (non-REM, REM, etc). But sleeping and waking are relatively discrete events and the time spent between both is easily quantifiable. \n",
    "\n",
    "Now, consider another metric that may influence the results of a test, like subject interest. Generally, one might think that a person who is more interested in a subject will do better on a test. But how do you measure interest? It's a pretty complicated problem because interest level is not easily defined. It's like defining happiness, or something.\n",
    "\n",
    "And back to our network. In theory, if we provide more data, the accuracy for our network should increase. We're going to include data for the following:\n",
    "- The total number of hours studied\n",
    "- Daily average hours spent playing video games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85de9d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Vector{Float64}:\n",
       " 3.25\n",
       " 5.5\n",
       " 4.5\n",
       " 2.0\n",
       " 1.5\n",
       " 9.25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additional input data\n",
    "study_hours      = [2.25, 7.00, 0.50, 12.0, 10.5, 4.75]\n",
    "video_game_hours = [3.25, 5.50, 4.50, 2.00, 1.50, 9.25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cc9bea",
   "metadata": {},
   "source": [
    "Because we added more metrics, we need to change the shape of our input and the network. Let's `zip` our input data so we get a tuple of every metric for each entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09327a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip([6.5, 8.25, 8.0, 5.75, 4.0, 9.0], [2.25, 7.0, 0.5, 12.0, 10.5, 4.75], [3.25, 5.5, 4.5, 2.0, 1.5, 9.25])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a list of tuples for each entry\n",
    "input_list = zip(sleep_hours, study_hours, video_game_hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d843725",
   "metadata": {},
   "source": [
    "And to index the first entry, we do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1c9bc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.5, 2.25, 3.25)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing first entry\n",
    "collect(input_list)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cab194",
   "metadata": {},
   "source": [
    "An entry represents a single person's data. So the first entry (above) describes a person who slept 6.5 hours the night before, studied a total of 2.25 hours, and plays about 3.25 hours of video games per day.\n",
    "\n",
    "Now, let's modify our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cad83d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_network (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function neural_network(entry, weights)\n",
    "    @assert length(entry) == length(weights) \"The entry tuple and weight tuple should have the same length.\"\n",
    "    \n",
    "    weighted_sum = 0\n",
    "    # x, m, as in, y = mx + b\n",
    "    for (x, m) in zip(entry, weights)\n",
    "        weighted_sum += x * m\n",
    "    end\n",
    "    \n",
    "    return weighted_sum\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de3f3ca",
   "metadata": {},
   "source": [
    "Our network looks very different from our old version. So instead of returning the product of a single weight value and input value, our neural network returns the sum of products of the inputs with their respective weight values.\n",
    "\n",
    "Note that because we increased our input size, we also need to increase the number of weights in our network. Like last time, we're going to assign them arbitrarily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c842e4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float64}:\n",
       "  0.5\n",
       "  0.0\n",
       " -0.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [0.5, 0.0, -0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a8f35",
   "metadata": {},
   "source": [
    "And now let's just pass in an entry and the weights into our neural network and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15188c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 2.60"
     ]
    }
   ],
   "source": [
    "entry = collect(input_list)[1]\n",
    "\n",
    "# Making a prediction\n",
    "prediction = neural_network(entry, weights)\n",
    "\n",
    "# Printing the result\n",
    "@printf \"Prediction: %.2f\" prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a325a03",
   "metadata": {},
   "source": [
    "This number is still pretty meaningless to us because of the arbitrary weights. It also goes out of our expected prediction range of 0.0 and 1.0. But that's okay. The important thing at this stage is that our network takes multiple weights and inputs and spits out _some_ number without throwing an error.\n",
    "\n",
    "## The Dot Product\n",
    "But let's take a moment to think about why it makes sense to use the dot product operation when constructing this neural network. In general terms, the dot product is an operation that takes multiple numbers and returns a single number. This is more or less what we want. We want to provide our network with a set of inputs and receive a single output. And now the next question to ask is: why do we multiply the inputs by a set of weights?\n",
    "\n",
    "The weights give us a mathematical way of manipulating the inputs. More specifically, they allow us to increase or decrease emphasis of an input. Let's consider the following weights and inputs:\n",
    "\n",
    "$$\n",
    "\\text{inputs} = \n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3\\\\\n",
    "a & b & c\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
