{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d26a9a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0132d9a4",
   "metadata": {},
   "source": [
    "# The MNIST Dataset\n",
    "We'll start building our first neural network with the MNIST dataset. The MNIST dataset contains 70,000 labeled images of handwritten digits. The goal of our neural network is to train it to discern handwritten digits as accurately as possible.\n",
    "\n",
    "In machine learning, you want to break your data into two sets: training data and testing data. Neural networks learn by consuming training data and adjust their network accordingly to more accurately detect the next piece of data. After you train your network, you'll want to assess its accuracy on data is has not seen before. This is where the test data comes handy. Rather than consuming and tuning, the network will simply consume test data and report its accuracy. This gives an idea of how it would perform under general circumstances.\n",
    "\n",
    "Let's go ahead and load the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6db2957e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac690a3",
   "metadata": {},
   "source": [
    "## Exploring The Data\n",
    "Let's get a better idea of what the data looks like by printing out the shape of both the training and testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea9834d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (60000, 28, 28)\n",
      "y_train shape:  (60000,)\n",
      "x_test shape:  (10000, 28, 28)\n",
      "y_test shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"x_test shape: \", x_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f15ab1e",
   "metadata": {},
   "source": [
    "The shape of the data tells us a few things. First, we can see that there are 60,000 training images and 10,000 testing images. We can gather that the images are 28 pixels wide by 28 pixels long and that `y_train` and `y_test` contain label data. Let's double check to make sure our assumptions are true.\n",
    "\n",
    "Let's print out the first piece of data from `x_train` and see what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cb49ef7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d550968",
   "metadata": {},
   "source": [
    "If you take a glance at the data, you can see you have values ranging from 0 to about 250. We can take a pretty confident guess that this is 8-bit pixel data (with the max pixel value being $2^8-1 = 255$). We're going to assume that the test data is similar as well, but feel free to double-check for your own sanity's sake.\n",
    "\n",
    "Now, let's print out the first piece of data from `y_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f408c687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dd9ef1",
   "metadata": {},
   "source": [
    "Hmm. `5` doesn't really give us much to go on, so let's instead print the minimum and maximum values of `y_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f2c41a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value:  9\n",
      "Minimum value:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum value: \", max(y_train))\n",
    "print(\"Minimum value: \", min(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9adbf74",
   "metadata": {},
   "source": [
    "It looks like we have 10 different labels, which makes sense because there's only 10 digits in our base-10 notation.\n",
    "\n",
    "We played a little dumb in this section for the sake of exploration. We didn't have to do as much digging as we did and could instead have deduced most of this information by the shape of the dataset alone. But I always err on the side of double checking your assumptions.\n",
    "\n",
    "For clarity, let's name our datasets something a little more verbose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57243d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aliasing the test data\n",
    "training_images = x_train\n",
    "training_labels = y_train\n",
    "test_images = x_test\n",
    "test_labels = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfb9723",
   "metadata": {},
   "source": [
    "## Displaying The Data\n",
    "This step isn't necessary in the machine learning pipeline. Our neural network doesn't need to \"see\" our data perse, but it definitely helps us understand our data a little better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff9c7fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9211c332",
   "metadata": {},
   "source": [
    "After importing `matplotlib`, we can display the data. Let's do the first five training images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "386580b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'training_images[4]')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1332x756 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying first five images\n",
    "fig, axs = plt.subplots(1, 5)\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "axs[0].imshow(training_images[0, :, :])\n",
    "axs[0].set_title(\"training_images[0]\")\n",
    "axs[1].imshow(training_images[1, :, :])\n",
    "axs[1].set_title(\"training_images[1]\")\n",
    "axs[2].imshow(training_images[2, :, :])\n",
    "axs[2].set_title(\"training_images[2]\")\n",
    "axs[3].imshow(training_images[3, :, :])\n",
    "axs[3].set_title(\"training_images[3]\")\n",
    "axs[4].imshow(training_images[4, :, :])\n",
    "axs[4].set_title(\"training_images[4]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7546584",
   "metadata": {},
   "source": [
    "And we can see this matches up with the label data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "853bafe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9]\n"
     ]
    }
   ],
   "source": [
    "print(training_labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39611cba",
   "metadata": {},
   "source": [
    "## Data Prepping\n",
    "Before we get into constructing and training the neural network, we need to prepare our data for consumption.\n",
    "\n",
    "First we're going to reshape the image data by flattening it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c56e644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening the image data\n",
    "training_images = tf.reshape(x_train, [-1, 28*28])\n",
    "test_images = tf.reshape(x_test, [-1, 28*28])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5491ed6c",
   "metadata": {},
   "source": [
    "Just to make sure, let's print out one of these images to make sure we reshaped them okay. They won't display because the pixel data is now in a single vector, but we can take just one image and reshape it back to its original 28x28 dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4a6610f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8d00979790>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tf.reshape(training_images[42], [28, 28]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf2e347",
   "metadata": {},
   "source": [
    "Looks pretty good to me. I'm assuming the `-1` in the `reshape` parameter is used to flatten whatever wasn't specified in the shape. For example, if we run `tf.reshape(x_train, [28, -1, 4])`, I'm expecting we will get a tensor shape of (28, 7\\*60000, 4). Feel free to run it yourself to check.\n",
    "\n",
    "We're not quite done yet. We still have to normalize the data to values between 0 and 1. Since our values are `uint8`, we're going to have to cast them as floats before normalizing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfe96992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize image data\n",
    "training_images = tf.dtypes.cast(training_images, tf.float32) / 255.0\n",
    "test_images = tf.dtypes.cast(test_images, tf.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5399d29",
   "metadata": {},
   "source": [
    "Now our data should be good to go 👍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90b8d80",
   "metadata": {},
   "source": [
    "# The Neural Network\n",
    "Finally, we're going to construct the neural network. We're going to ignore a few minor implementation details, but after we have it running, it should be pretty intuitive what is going on.\n",
    "\n",
    "Let's create the structure of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b6dd319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(10),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45f66c6",
   "metadata": {},
   "source": [
    "Our network consists of three layers, including an output layer. The first layer has 512 nodes and the second has 256 nodes. The output layer has only 10 nodes which will denote the confidence values that a particular image is a certain digit.\n",
    "\n",
    "Now, we're going to compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb69a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8869a9",
   "metadata": {},
   "source": [
    "Finally, we can train the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9019ee62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 - 3s - loss: 0.1858 - accuracy: 0.9437\n",
      "Epoch 2/5\n",
      "1875/1875 - 2s - loss: 0.0796 - accuracy: 0.9752\n",
      "Epoch 3/5\n",
      "1875/1875 - 2s - loss: 0.0544 - accuracy: 0.9823\n",
      "Epoch 4/5\n",
      "1875/1875 - 2s - loss: 0.0410 - accuracy: 0.9872\n",
      "Epoch 5/5\n",
      "1875/1875 - 3s - loss: 0.0310 - accuracy: 0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8d007e0d60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(training_images, training_labels, batch_size=32, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dda9c68",
   "metadata": {},
   "source": [
    "Our next step is to test how well our network performs on data it has never seen before. This is where our test set comes in handy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f047933f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0884 - accuracy: 0.9779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08842284232378006, 0.9779000282287598]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model's performance\n",
    "model.evaluate(test_images, test_labels, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812f6f06",
   "metadata": {},
   "source": [
    "Running the evaluation, you'll get roughly about a 97% to 98% accuracy, which is pretty good. Note that the accuracy during evaluation might be a little lower than the accuracy at the end of training. This makes sense because the network will slightly increase its fit to the training data after each training iteration, so the network will become more and more sensitive to any details that diverges from the training dataset. This is a phenomena known as _overfitting_."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
