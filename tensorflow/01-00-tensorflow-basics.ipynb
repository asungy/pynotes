{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Is A Tensor?\n",
    "Simply put, a tensor is a collection of values. It can be a single value, one-dimensional, or multi-dimensional. \n",
    "![Visual Diagram of Tensor](https://miro.medium.com/max/700/0*jGB1CGQ9HdeUwlgB)\n",
    "In mathematical terms, an $n^{th}$-rank tensor in $m$-dimensional space has $n$ indices and $m^n$ components. The image above may suggest that rank and dimensionality are the same. Mathematically-speaking, they are not. But for our purposes, we can think of them as the same thing.\n",
    "\n",
    "In Tensorflow, all tensors have a uniform type or `dtype` (a list of `dtype`s can be found [here](https://www.tensorflow.org/api_docs/python/tf/dtypes/DType)). Let's first create a \"scalar\" or \"rank-0\" tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# A rank-0 tensor\n",
    "rank_0_tensor = tf.constant(4)\n",
    "print(rank_0_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the tensor value is displayed as the first parameter and the `int32` as the last parameter. Notice, however, that the second parameter `shape` is empty. We will go over the `shape` parameter shortly.\n",
    "\n",
    "Let's implement a rank-1 tensor (or a vector):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 3.14   1.592  6.    -5.   ], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# A rank-1 tensor\n",
    "rank_1_tensor = tf.constant([3.14, 1.592, 6, -5])\n",
    "print(rank_1_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is are pretty self-explanatory from the rank-0 tensor. Notice that the `dtype` is now a `float32` because we specified some floating-point values. \n",
    "\n",
    "Here's a rank-2 tensor (or matrix):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# A rank-2 tensor\n",
    "rank_2_tensor = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(rank_2_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's a rank-4 tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A rank-4 tensor\n",
    "rank_4_tensor = tf.constant([\n",
    "    [[[1, 2], [3, 4]], [[5, 6], [7, 8]]], [[[1, 2], [3, 4]], [[5, 6], [7, 8]]], [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n",
    "    [[[1, 2], [3, 4]], [[5, 6], [7, 8]]], [[[1, 2], [3, 4]], [[5, 6], [7, 8]]], [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n",
    "    [[[1, 2], [3, 4]], [[5, 6], [7, 8]]], [[[1, 2], [3, 4]], [[5, 6], [7, 8]]], [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a few tensors under our belt, let's take a look at the `shape` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank-0:  ()\n",
      "Rank-1:  (4,)\n",
      "Rank-2:  (3, 3)\n",
      "Rank-4:  (9, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Rank-0: \", rank_0_tensor.shape)\n",
    "print(\"Rank-1: \", rank_1_tensor.shape)\n",
    "print(\"Rank-2: \", rank_2_tensor.shape)\n",
    "print(\"Rank-4: \", rank_4_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `shape` tuple can tell us a lot about the structure of a tensor. It's elements tell us about the length of a particular axis in the tensor. Notice that the length of the tuple tells us the rank of the tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Basics\n",
    "Now that we understand the basics of a tensor, let's do some simple computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 6  8]\n",
      " [10 12]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 5 12]\n",
      " [21 32]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[19 22]\n",
      " [43 50]], shape=(2, 2), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "])\n",
    "\n",
    "b = tf.constant([\n",
    "    [5, 6],\n",
    "    [7, 8]\n",
    "])\n",
    "\n",
    "# Element-wise addition\n",
    "add = tf.add(a, b)\n",
    "\n",
    "# Element-wise multiplication\n",
    "multiply = tf.multiply(a, b)\n",
    "\n",
    "# Matrix multiplication\n",
    "matmul = tf.matmul(a, b)\n",
    "\n",
    "print(add, '\\n')\n",
    "print(multiply, '\\n')\n",
    "print(matmul, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operators like `+`, `-`, and `*` have been overriden in Tensorflow to make computations look a little more succinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 6  8]\n",
      " [10 12]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[-4 -4]\n",
      " [-4 -4]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 5 12]\n",
      " [21 32]], shape=(2, 2), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(a + b, '\\n')\n",
    "print(a - b, '\\n')\n",
    "print(a * b, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few more overriden operators. Can you guess what they do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[   1   32]\n",
      " [ 243 1024]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[19 22]\n",
      " [43 50]], shape=(2, 2), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(a ** 5, '\\n')\n",
    "print(a @ b, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also initialize tensors in different ways using `tf.ones`, `tf.zeros`, and `tf.eye`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(3, 3), dtype=float32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]], shape=(2, 4), dtype=float32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]], shape=(3, 3), dtype=float32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A matrix full of 1s\n",
    "ones = tf.ones((3, 3))\n",
    "\n",
    "# A matrix full of 0s\n",
    "zeros = tf.zeros((2, 4))\n",
    "\n",
    "# An identity matrix\n",
    "eye = tf.eye(3)\n",
    "\n",
    "print(ones, '\\n')\n",
    "print(zeros, '\\n')\n",
    "print(eye, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are also a few randomly generated tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.06072164 -0.69348675  0.6977107 ]\n",
      " [ 0.8282165  -1.4546869  -0.7995216 ]\n",
      " [ 1.7773803   1.4272352   1.4893292 ]], shape=(3, 3), dtype=float32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[[ 3. 23. 79.]\n",
      "  [ 5. 24. 68.]]\n",
      "\n",
      " [[ 5. 11. 63.]\n",
      "  [ 2. 12. 58.]]\n",
      "\n",
      " [[ 6. 16. 64.]\n",
      "  [ 3. 14. 64.]]], shape=(3, 2, 3), dtype=float32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[[4.0439650e-02 1.6006520e+00 3.9261093e+00]\n",
      "  [3.0370793e-01 1.7312568e+00 3.5833294e+00]\n",
      "  [2.9998809e-01 2.4647996e+00 1.2586108e+00]\n",
      "  [2.3612045e-01 8.3665234e-01 2.6893842e+00]]\n",
      "\n",
      " [[4.5333186e-01 2.2772911e+00 8.5172329e+00]\n",
      "  [1.6875120e-03 6.6614830e-01 2.7921131e+00]\n",
      "  [5.6562078e-01 1.5632170e+00 4.2659278e+00]\n",
      "  [3.1484112e-01 1.0792449e+00 3.6364675e+00]]\n",
      "\n",
      " [[9.7452855e-01 5.9072089e-01 3.2466924e+00]\n",
      "  [5.3994876e-01 1.0063773e+00 1.7456955e+00]\n",
      "  [3.9032882e-01 2.5593288e+00 3.2262855e+00]\n",
      "  [1.6132869e+00 7.8156400e-01 5.3831863e+00]]], shape=(3, 4, 3), dtype=float32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tensor with values of a normal distribution\n",
    "normal = tf.random.normal((3, 3), mean=0, stddev=1)\n",
    "\n",
    "# Tensor with values of a Poisson distribution\n",
    "poisson = tf.random.poisson(\n",
    "    shape=(3, 2),\n",
    "    lam=[3.14, 15.92, 65.35]\n",
    ")\n",
    "\n",
    "# Tensor with values of a Gamma distribution\n",
    "gamma = tf.random.gamma(\n",
    "    shape=(3, 4),\n",
    "    alpha=[1.11, 2.22, 3.33]\n",
    ")\n",
    "\n",
    "print(normal, '\\n')\n",
    "print(poisson, '\\n')\n",
    "print(gamma, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are only a few of many ways to initialize a tensor with Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow follows standard Python array indexing, as you'd expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32) \n",
      "\n",
      "tf.Tensor([4 5 6], shape=(3,), dtype=int32) \n",
      "\n",
      "tf.Tensor([7 8 9], shape=(3,), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "\n",
    "print(a[0], '\\n')\n",
    "print(a[1], '\\n')\n",
    "print(a[2], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that indexing a rank-2 tensor like this returns a rank-1 tensor. We can get the last tensor by negative indexing as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([7 8 9], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(a[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get slices of a tensor with a colon `:`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All elements: [0 1 2 3 4 5 6 7 8]\n",
      "Before third element: [0 1 2]\n",
      "From fourth element to end: [4 5 6 7 8]\n",
      "Elements between 4 and 7 (inclusive, exclusive): [4 5 6]\n",
      "Reversed: [8 7 6 5 4 3 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
    "print(\"All elements:\", a[:].numpy())\n",
    "print(\"Before third element:\", a[:3].numpy())\n",
    "print(\"From fourth element to end:\", a[4:].numpy())\n",
    "print(\"Elements between 4 and 7 (inclusive, exclusive):\", a[4:7].numpy())\n",
    "print(\"Reversed:\", a[::-1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to index the following rank-3 tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_3_tensor = tf.constant([\n",
    "    [[0, 1, 2, 3, 4],\n",
    "     [5, 6, 7, 8, 9]],\n",
    "    [[10, 11, 12, 13, 14],\n",
    "     [15, 16, 17, 18, 19]], \n",
    "    [[20, 21, 22, 23, 24],\n",
    "     [25, 26, 27, 28, 29]]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an image to help visualize this tensor:\n",
    "![image of rank-3 tensor](https://www.tensorflow.org/guide/images/tensor/index1.png)\n",
    "\n",
    "Indexing multi-axial tensors works the same way as indexing a single-axis one. Here we're going to extract each 'layer' of the tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First layer:\n",
      " [[0 1 2 3 4]\n",
      " [5 6 7 8 9]] \n",
      "\n",
      "Second layer:\n",
      " [[10 11 12 13 14]\n",
      " [15 16 17 18 19]] \n",
      "\n",
      "Third layer:\n",
      " [[20 21 22 23 24]\n",
      " [25 26 27 28 29]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Indexing by layer\n",
    "print(\"First layer:\\n\",  rank_3_tensor[0, :].numpy(), '\\n')\n",
    "print(\"Second layer:\\n\", rank_3_tensor[1, :].numpy(), '\\n')\n",
    "print(\"Third layer:\\n\",  rank_3_tensor[2, :].numpy(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to extract the last column of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last column of first layer:\n",
      " [4 9] \n",
      "\n",
      "Last column of second layer:\n",
      " [14 19] \n",
      "\n",
      "Last column of third layer:\n",
      " [24 29] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting the last column of each layer\n",
    "print(\"Last column of first layer:\\n\",  rank_3_tensor[0, :, -1].numpy(), '\\n')\n",
    "print(\"Last column of second layer:\\n\", rank_3_tensor[1, :, -1].numpy(), '\\n')\n",
    "print(\"Last column of third layer:\\n\",  rank_3_tensor[2, :, -1].numpy(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's try to index the bottom center value of every layer in a single call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7 17 27]\n"
     ]
    }
   ],
   "source": [
    "# Bottom center value of every layer\n",
    "print(rank_3_tensor[:, 1, 2].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We understand the basics of tensor shapes. Let's learn how to manipulate them.\n",
    "\n",
    "Here, we have a rank-1 tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17], shape=(18,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "rank_1_tensor = tf.range(0, 18)\n",
    "print(rank_1_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reshape this into a rank-2 tensor or a rank-3 tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank-2 Tensor:\n",
      " tf.Tensor(\n",
      "[[ 0  1]\n",
      " [ 2  3]\n",
      " [ 4  5]\n",
      " [ 6  7]\n",
      " [ 8  9]\n",
      " [10 11]\n",
      " [12 13]\n",
      " [14 15]\n",
      " [16 17]], shape=(9, 2), dtype=int32) \n",
      "\n",
      "Rank-3 Tensor:\n",
      " tf.Tensor(\n",
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]\n",
      "  [ 6  7  8]]\n",
      "\n",
      " [[ 9 10 11]\n",
      "  [12 13 14]\n",
      "  [15 16 17]]], shape=(2, 3, 3), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reshaping into a rank-2 tensor\n",
    "rank_2_tensor = tf.reshape(rank_1_tensor, (9, 2))\n",
    "rank_3_tensor = tf.reshape(rank_1_tensor, (2, 3, 3))\n",
    "\n",
    "print(\"Rank-2 Tensor:\\n\", rank_2_tensor, '\\n')\n",
    "print(\"Rank-3 Tensor:\\n\", rank_3_tensor, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
